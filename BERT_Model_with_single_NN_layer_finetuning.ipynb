{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "BERT Model with single NN layer finetuning.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kd4NyN_Y-Sza",
        "colab_type": "code",
        "outputId": "1e82763b-9371-47cc-83a8-87fa20ebe18f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 306
        }
      },
      "source": [
        "import os\n",
        "import sys\n",
        "import json\n",
        "import datetime\n",
        "import pprint\n",
        "import tensorflow as tf\n",
        "\n",
        "# Authenticate, so we can access storage bucket and TPU\n",
        "from google.colab import auth\n",
        "auth.authenticate_user()\n",
        "\n",
        "# If you want to use TPU, first switch to tpu runtime in colab\n",
        "USE_TPU = True #@param{type:\"boolean\"}\n",
        "\n",
        "# We will use base uncased bert model, you can give try with large models\n",
        "# For large model TPU is necessary\n",
        "BERT_MODEL = 'uncased_L-12_H-768_A-12' #@param {type:\"string\"}\n",
        "\n",
        "# BERT checkpoint bucket\n",
        "BERT_PRETRAINED_DIR = 'gs://cloud-tpu-checkpoints/bert/' + BERT_MODEL\n",
        "print('***** BERT pretrained directory: {} *****'.format(BERT_PRETRAINED_DIR))\n",
        "!gsutil ls $BERT_PRETRAINED_DIR\n",
        "\n",
        "# Bucket for saving checkpoints and outputs\n",
        "BUCKET = 'quorabert_ml' #@param {type:\"string\"}\n",
        "if BUCKET!=\"\":\n",
        "  OUTPUT_DIR = 'gs://{}/outputs'.format(BUCKET)\n",
        "  tf.gfile.MakeDirs(OUTPUT_DIR)\n",
        "elif USE_TPU:\n",
        "  raise ValueError('Must specify an existing GCS bucket name for running on TPU')\n",
        "else:\n",
        "  OUTPUT_DIR = 'out_dir'\n",
        "  os.mkdir(OUTPUT_DIR)\n",
        "print('***** Model output directory: {} *****'.format(OUTPUT_DIR))\n",
        "\n",
        "if USE_TPU:\n",
        "  # getting info on TPU runtime\n",
        "  assert 'COLAB_TPU_ADDR' in os.environ, 'ERROR: Not connected to a TPU runtime; Change notebook runtype to TPU'\n",
        "  TPU_ADDRESS = 'grpc://' + os.environ['COLAB_TPU_ADDR']\n",
        "  print('TPU address is', TPU_ADDRESS)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:\n",
            "The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
            "For more information, please see:\n",
            "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
            "  * https://github.com/tensorflow/addons\n",
            "  * https://github.com/tensorflow/io (for I/O related ops)\n",
            "If you depend on functionality not listed there, please file an issue.\n",
            "\n",
            "***** BERT pretrained directory: gs://cloud-tpu-checkpoints/bert/uncased_L-12_H-768_A-12 *****\n",
            "gs://cloud-tpu-checkpoints/bert/uncased_L-12_H-768_A-12/bert_config.json\n",
            "gs://cloud-tpu-checkpoints/bert/uncased_L-12_H-768_A-12/bert_model.ckpt.data-00000-of-00001\n",
            "gs://cloud-tpu-checkpoints/bert/uncased_L-12_H-768_A-12/bert_model.ckpt.index\n",
            "gs://cloud-tpu-checkpoints/bert/uncased_L-12_H-768_A-12/bert_model.ckpt.meta\n",
            "gs://cloud-tpu-checkpoints/bert/uncased_L-12_H-768_A-12/checkpoint\n",
            "gs://cloud-tpu-checkpoints/bert/uncased_L-12_H-768_A-12/vocab.txt\n",
            "***** Model output directory: gs://quorabert_ml/outputs *****\n",
            "TPU address is grpc://10.36.151.90:8470\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lg-Zy29n_gL7",
        "colab_type": "code",
        "outputId": "7d40136c-b790-4ee1-b9be-a5bb18b79939",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        }
      },
      "source": [
        "# Clone BERT repo and add bert in system path\n",
        "!test -d bert || git clone -q https://github.com/google-research/bert.git\n",
        "if not 'bert' in sys.path:\n",
        "  sys.path += ['bert']\n",
        "# Download QQP Task dataset present in GLUE Tasks.\n",
        "TASK_DATA_DIR = 'glue_data/QQP'\n",
        "!test -d glue_data || git clone https://gist.github.com/60c2bdb54d156a41194446737ce03e2e.git glue_data\n",
        "!test -d $TASK_DATA_DIR || python glue_data/download_glue_data.py --data_dir glue_data --tasks=QQP\n",
        "!ls -als $TASK_DATA_DIRimport sys\n",
        "\n",
        "sys.path.append('bert/')\n",
        "\n",
        "from __future__ import absolute_import\n",
        "from __future__ import division\n",
        "from __future__ import print_function\n",
        "\n",
        "import codecs\n",
        "import collections\n",
        "import json\n",
        "import re\n",
        "import os\n",
        "import pprint\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "\n",
        "import modeling\n",
        "import tokenization"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'glue_data'...\n",
            "remote: Enumerating objects: 21, done.\u001b[K\n",
            "remote: Total 21 (delta 0), reused 0 (delta 0), pack-reused 21\u001b[K\n",
            "Unpacking objects:   4% (1/21)   \rUnpacking objects:   9% (2/21)   \rUnpacking objects:  14% (3/21)   \rUnpacking objects:  19% (4/21)   \rUnpacking objects:  23% (5/21)   \rUnpacking objects:  28% (6/21)   \rUnpacking objects:  33% (7/21)   \rUnpacking objects:  38% (8/21)   \rUnpacking objects:  42% (9/21)   \rUnpacking objects:  47% (10/21)   \rUnpacking objects:  52% (11/21)   \rUnpacking objects:  57% (12/21)   \rUnpacking objects:  61% (13/21)   \rUnpacking objects:  66% (14/21)   \rUnpacking objects:  71% (15/21)   \rUnpacking objects:  76% (16/21)   \rUnpacking objects:  80% (17/21)   \rUnpacking objects:  85% (18/21)   \rUnpacking objects:  90% (19/21)   \rUnpacking objects:  95% (20/21)   \rUnpacking objects: 100% (21/21)   \rUnpacking objects: 100% (21/21), done.\n",
            "Downloading and extracting QQP...\n",
            "\tCompleted!\n",
            "ls: cannot access 'sys': No such file or directory\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1eYZ0s-WBhaU",
        "colab_type": "code",
        "outputId": "b37be740-753c-4bfd-d851-7e65055e4dbb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "import modeling\n",
        "import optimization\n",
        "import tokenization\n",
        "import run_classifier\n",
        "\n",
        "# Model Hyper Parameters\n",
        "TRAIN_BATCH_SIZE = 32 # For GPU, reduce to 16\n",
        "EVAL_BATCH_SIZE = 8\n",
        "PREDICT_BATCH_SIZE = 8\n",
        "LEARNING_RATE = 2e-5\n",
        "NUM_TRAIN_EPOCHS = 3.0\n",
        "WARMUP_PROPORTION = 0.1\n",
        "MAX_SEQ_LENGTH = 200 \n",
        "\n",
        "# Model configs\n",
        "SAVE_CHECKPOINTS_STEPS = 1000\n",
        "ITERATIONS_PER_LOOP = 1000\n",
        "NUM_TPU_CORES = 8\n",
        "VOCAB_FILE = os.path.join(BERT_PRETRAINED_DIR, 'vocab.txt')\n",
        "CONFIG_FILE = os.path.join(BERT_PRETRAINED_DIR, 'bert_config.json')\n",
        "INIT_CHECKPOINT = os.path.join(BERT_PRETRAINED_DIR, 'bert_model.ckpt')\n",
        "DO_LOWER_CASE = BERT_MODEL.startswith('uncased')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From bert/optimization.py:87: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L9zpWsb1Bnky",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class QQPProcessor(run_classifier.DataProcessor):\n",
        "  \"\"\"Processor for the Quora Question pair data set.\"\"\"\n",
        "\n",
        "  def get_train_examples(self, data_dir):\n",
        "    \"\"\"Reading train.tsv and converting to list of InputExample\"\"\"\n",
        "    return self._create_examples(\n",
        "        self._read_tsv(os.path.join(data_dir,\"train.tsv\")), 'train')\n",
        "\n",
        "  def get_dev_examples(self, data_dir):\n",
        "    \"\"\"Reading dev.tsv and converting to list of InputExample\"\"\"\n",
        "    return self._create_examples(\n",
        "        self._read_tsv(os.path.join(data_dir,\"dev.tsv\")), 'dev')\n",
        "  \n",
        "  def get_test_examples(self, data_dir):\n",
        "    \"\"\"Reading train.tsv and converting to list of InputExample\"\"\"\n",
        "    return self._create_examples(\n",
        "        self._read_tsv(os.path.join(data_dir,\"test.tsv\")), 'test')\n",
        "  \n",
        "  def get_predict_examples(self, sentence_pairs):\n",
        "    \"\"\"Given question pairs, conevrting to list of InputExample\"\"\"\n",
        "    examples = []\n",
        "    for (i, qpair) in enumerate(sentence_pairs):\n",
        "      guid = \"predict-%d\" % (i)\n",
        "      # converting questions to utf-8 and creating InputExamples\n",
        "      text_a = tokenization.convert_to_unicode(qpair[0])\n",
        "      text_b = tokenization.convert_to_unicode(qpair[1])\n",
        "      # We will add label  as 0, because None is not supported in converting to features\n",
        "      examples.append(\n",
        "          run_classifier.InputExample(guid=guid, text_a=text_a, text_b=text_b, label=0))\n",
        "    return examples\n",
        "  \n",
        "  def _create_examples(self, lines, set_type):\n",
        "    \"\"\"Creates examples for the training, dev and test sets.\"\"\"\n",
        "    examples = []\n",
        "    for (i, line) in enumerate(lines):\n",
        "      guid = \"%s-%d\" % (set_type, i)\n",
        "      if set_type=='test':\n",
        "        # removing header and invalid data\n",
        "        if i == 0 or len(line)!=3:\n",
        "          print(guid, line)\n",
        "          continue\n",
        "        text_a = tokenization.convert_to_unicode(line[1])\n",
        "        text_b = tokenization.convert_to_unicode(line[2])\n",
        "        label = 0 # We will use zero for test as convert_example_to_features doesn't support None\n",
        "      else:\n",
        "        # removing header and invalid data\n",
        "        if i == 0 or len(line)!=6:\n",
        "          continue\n",
        "        text_a = tokenization.convert_to_unicode(line[3])\n",
        "        text_b = tokenization.convert_to_unicode(line[4])\n",
        "        label = int(line[5])\n",
        "      examples.append(\n",
        "          run_classifier.InputExample(guid=guid, text_a=text_a, text_b=text_b, label=label))\n",
        "    return examples\n",
        "\n",
        "  def get_labels(self):\n",
        "    \"return class labels\"\n",
        "    return [0,1]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tu_jZ3LyB5rA",
        "colab_type": "code",
        "outputId": "783a0c69-b467-4fca-aa7c-90c059597d2b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "processor = QQPProcessor()\n",
        "label_list = processor.get_labels()\n",
        "tokenizer = tokenization.FullTokenizer(vocab_file=VOCAB_FILE, do_lower_case=DO_LOWER_CASE)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From bert/tokenization.py:125: The name tf.gfile.GFile is deprecated. Please use tf.io.gfile.GFile instead.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ops8TuYaB9oa",
        "colab_type": "code",
        "outputId": "7f31a3c1-a4d5-41d6-f027-82021776ae62",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "print(\"################  Processing Training Data #####################\")\n",
        "TRAIN_TF_RECORD = os.path.join(OUTPUT_DIR, \"train.tf_record\")\n",
        "train_examples = processor.get_train_examples(TASK_DATA_DIR)\n",
        "num_train_examples = len(train_examples)\n",
        "num_train_steps = int( num_train_examples / TRAIN_BATCH_SIZE * NUM_TRAIN_EPOCHS)\n",
        "num_warmup_steps = int(num_train_steps * WARMUP_PROPORTION)\n",
        "run_classifier.file_based_convert_examples_to_features(train_examples, label_list, MAX_SEQ_LENGTH, tokenizer, TRAIN_TF_RECORD)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "################  Processing Training Data #####################\n",
            "WARNING:tensorflow:From bert/run_classifier.py:199: The name tf.gfile.Open is deprecated. Please use tf.io.gfile.GFile instead.\n",
            "\n",
            "WARNING:tensorflow:From bert/run_classifier.py:483: The name tf.python_io.TFRecordWriter is deprecated. Please use tf.io.TFRecordWriter instead.\n",
            "\n",
            "WARNING:tensorflow:From bert/run_classifier.py:487: The name tf.logging.info is deprecated. Please use tf.compat.v1.logging.info instead.\n",
            "\n",
            "INFO:tensorflow:Writing example 0 of 363849\n",
            "INFO:tensorflow:*** Example ***\n",
            "INFO:tensorflow:guid: train-1\n",
            "INFO:tensorflow:tokens: [CLS] how is the life of a math student ? could you describe your own experiences ? [SEP] which level of prep ##ration is enough for the exam j ##lp ##t ##5 ? [SEP]\n",
            "INFO:tensorflow:input_ids: 101 2129 2003 1996 2166 1997 1037 8785 3076 1029 2071 2017 6235 2115 2219 6322 1029 102 2029 2504 1997 17463 8156 2003 2438 2005 1996 11360 1046 14277 2102 2629 1029 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:label: 0 (id = 0)\n",
            "INFO:tensorflow:*** Example ***\n",
            "INFO:tensorflow:guid: train-2\n",
            "INFO:tensorflow:tokens: [CLS] how do i control my horn ##y emotions ? [SEP] how do you control your horn ##iness ? [SEP]\n",
            "INFO:tensorflow:input_ids: 101 2129 2079 1045 2491 2026 7109 2100 6699 1029 102 2129 2079 2017 2491 2115 7109 9961 1029 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:label: 1 (id = 1)\n",
            "INFO:tensorflow:*** Example ***\n",
            "INFO:tensorflow:guid: train-3\n",
            "INFO:tensorflow:tokens: [CLS] what causes stool color to change to yellow ? [SEP] what can cause stool to come out as little balls ? [SEP]\n",
            "INFO:tensorflow:input_ids: 101 2054 5320 14708 3609 2000 2689 2000 3756 1029 102 2054 2064 3426 14708 2000 2272 2041 2004 2210 7395 1029 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:label: 0 (id = 0)\n",
            "INFO:tensorflow:*** Example ***\n",
            "INFO:tensorflow:guid: train-4\n",
            "INFO:tensorflow:tokens: [CLS] what can one do after mb ##bs ? [SEP] what do i do after my mb ##bs ? [SEP]\n",
            "INFO:tensorflow:input_ids: 101 2054 2064 2028 2079 2044 16914 5910 1029 102 2054 2079 1045 2079 2044 2026 16914 5910 1029 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:label: 1 (id = 1)\n",
            "INFO:tensorflow:*** Example ***\n",
            "INFO:tensorflow:guid: train-5\n",
            "INFO:tensorflow:tokens: [CLS] where can i find a power outlet for my laptop at melbourne airport ? [SEP] would a second airport in sydney , australia be needed if a high - speed rail link was created between melbourne and sydney ? [SEP]\n",
            "INFO:tensorflow:input_ids: 101 2073 2064 1045 2424 1037 2373 13307 2005 2026 12191 2012 4940 3199 1029 102 2052 1037 2117 3199 1999 3994 1010 2660 2022 2734 2065 1037 2152 1011 3177 4334 4957 2001 2580 2090 4940 1998 3994 1029 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:label: 0 (id = 0)\n",
            "INFO:tensorflow:Writing example 10000 of 363849\n",
            "INFO:tensorflow:Writing example 20000 of 363849\n",
            "INFO:tensorflow:Writing example 30000 of 363849\n",
            "INFO:tensorflow:Writing example 40000 of 363849\n",
            "INFO:tensorflow:Writing example 50000 of 363849\n",
            "INFO:tensorflow:Writing example 60000 of 363849\n",
            "INFO:tensorflow:Writing example 70000 of 363849\n",
            "INFO:tensorflow:Writing example 80000 of 363849\n",
            "INFO:tensorflow:Writing example 90000 of 363849\n",
            "INFO:tensorflow:Writing example 100000 of 363849\n",
            "INFO:tensorflow:Writing example 110000 of 363849\n",
            "INFO:tensorflow:Writing example 120000 of 363849\n",
            "INFO:tensorflow:Writing example 130000 of 363849\n",
            "INFO:tensorflow:Writing example 140000 of 363849\n",
            "INFO:tensorflow:Writing example 150000 of 363849\n",
            "INFO:tensorflow:Writing example 160000 of 363849\n",
            "INFO:tensorflow:Writing example 170000 of 363849\n",
            "INFO:tensorflow:Writing example 180000 of 363849\n",
            "INFO:tensorflow:Writing example 190000 of 363849\n",
            "INFO:tensorflow:Writing example 200000 of 363849\n",
            "INFO:tensorflow:Writing example 210000 of 363849\n",
            "INFO:tensorflow:Writing example 220000 of 363849\n",
            "INFO:tensorflow:Writing example 230000 of 363849\n",
            "INFO:tensorflow:Writing example 240000 of 363849\n",
            "INFO:tensorflow:Writing example 250000 of 363849\n",
            "INFO:tensorflow:Writing example 260000 of 363849\n",
            "INFO:tensorflow:Writing example 270000 of 363849\n",
            "INFO:tensorflow:Writing example 280000 of 363849\n",
            "INFO:tensorflow:Writing example 290000 of 363849\n",
            "INFO:tensorflow:Writing example 300000 of 363849\n",
            "INFO:tensorflow:Writing example 310000 of 363849\n",
            "INFO:tensorflow:Writing example 320000 of 363849\n",
            "INFO:tensorflow:Writing example 330000 of 363849\n",
            "INFO:tensorflow:Writing example 340000 of 363849\n",
            "INFO:tensorflow:Writing example 350000 of 363849\n",
            "INFO:tensorflow:Writing example 360000 of 363849\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LHS1cjbbCBa7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def create_model(bert_config, is_training, input_ids, input_mask, segment_ids,\n",
        "                 labels, num_labels, use_one_hot_embeddings):\n",
        "  \"\"\"Creates a classification model.\"\"\"\n",
        "  # Bert Model instant \n",
        "  model = modeling.BertModel(\n",
        "      config=bert_config,\n",
        "      is_training=is_training,\n",
        "      input_ids=input_ids,\n",
        "      input_mask=input_mask,\n",
        "      token_type_ids=segment_ids,\n",
        "      use_one_hot_embeddings=use_one_hot_embeddings)\n",
        "\n",
        "  # Getting output for last layer of BERT\n",
        "  output_layer = model.get_pooled_output()\n",
        "  \n",
        "  # Number of outputs for last layer\n",
        "  hidden_size = output_layer.shape[-1].value\n",
        "  \n",
        "  # We will use one layer on top of BERT pretrained for creating classification model\n",
        "  output_weights = tf.get_variable(\n",
        "      \"output_weights\", [num_labels, hidden_size],\n",
        "      initializer=tf.truncated_normal_initializer(stddev=0.02))\n",
        "\n",
        "  output_bias = tf.get_variable(\n",
        "      \"output_bias\", [num_labels], initializer=tf.zeros_initializer())\n",
        "\n",
        "  with tf.variable_scope(\"loss\"):\n",
        "    if is_training:\n",
        "      # 0.1 dropout\n",
        "      output_layer = tf.nn.dropout(output_layer, keep_prob=0.9)\n",
        "    \n",
        "    # Calcaulte prediction probabilites and loss\n",
        "    logits = tf.matmul(output_layer, output_weights, transpose_b=True)\n",
        "    logits = tf.nn.bias_add(logits, output_bias)\n",
        "    probabilities = tf.nn.softmax(logits, axis=-1)\n",
        "    log_probs = tf.nn.log_softmax(logits, axis=-1)\n",
        "\n",
        "    one_hot_labels = tf.one_hot(labels, depth=num_labels, dtype=tf.float32)\n",
        "\n",
        "    per_example_loss = -tf.reduce_sum(one_hot_labels * log_probs, axis=-1)\n",
        "    loss = tf.reduce_mean(per_example_loss)\n",
        "\n",
        "    return (loss, per_example_loss, logits, probabilities)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iCKUnUuFFh5O",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def model_fn_builder(bert_config, num_labels, init_checkpoint, learning_rate,\n",
        "                     num_train_steps, num_warmup_steps, use_tpu,\n",
        "                     use_one_hot_embeddings):\n",
        "  \"\"\"Returns `model_fn` closure for TPUEstimator.\"\"\"\n",
        "\n",
        "  def model_fn(features, labels, mode, params):  \n",
        "    \"\"\"The `model_fn` for TPUEstimator.\"\"\"\n",
        "\n",
        "    # reading features input\n",
        "    input_ids = features[\"input_ids\"]\n",
        "    input_mask = features[\"input_mask\"]\n",
        "    segment_ids = features[\"segment_ids\"]\n",
        "    label_ids = features[\"label_ids\"]\n",
        "    is_real_example = None\n",
        "    if \"is_real_example\" in features:\n",
        "      is_real_example = tf.cast(features[\"is_real_example\"], dtype=tf.float32)\n",
        "    else:\n",
        "      is_real_example = tf.ones(tf.shape(label_ids), dtype=tf.float32)\n",
        "    \n",
        "    # checking if training mode\n",
        "    is_training = (mode == tf.estimator.ModeKeys.TRAIN)\n",
        "    \n",
        "    # create simple classification model\n",
        "    (total_loss, per_example_loss, logits, probabilities) = create_model(\n",
        "        bert_config, is_training, input_ids, input_mask, segment_ids, label_ids,\n",
        "        num_labels, use_one_hot_embeddings)\n",
        "    \n",
        "    # getting variables for intialization and using pretrained init checkpoint\n",
        "    tvars = tf.trainable_variables()\n",
        "    initialized_variable_names = {}\n",
        "    scaffold_fn = None\n",
        "    if init_checkpoint:\n",
        "      (assignment_map, initialized_variable_names\n",
        "      ) = modeling.get_assignment_map_from_checkpoint(tvars, init_checkpoint)\n",
        "      if use_tpu:\n",
        "\n",
        "        def tpu_scaffold():\n",
        "          tf.train.init_from_checkpoint(init_checkpoint, assignment_map)\n",
        "          return tf.train.Scaffold()\n",
        "\n",
        "        scaffold_fn = tpu_scaffold\n",
        "      else:\n",
        "        tf.train.init_from_checkpoint(init_checkpoint, assignment_map)\n",
        "\n",
        "    output_spec = None\n",
        "    if mode == tf.estimator.ModeKeys.TRAIN:\n",
        "      # defining optimizar function\n",
        "      train_op = optimization.create_optimizer(\n",
        "          total_loss, learning_rate, num_train_steps, num_warmup_steps, use_tpu)\n",
        "      \n",
        "      # Training estimator spec\n",
        "      output_spec = tf.contrib.tpu.TPUEstimatorSpec(\n",
        "          mode=mode,\n",
        "          loss=total_loss,\n",
        "          train_op=train_op,\n",
        "          scaffold_fn=scaffold_fn)\n",
        "    elif mode == tf.estimator.ModeKeys.EVAL:\n",
        "      # accuracy, loss, auc, F1, precision and recall metrics for evaluation\n",
        "      def metric_fn(per_example_loss, label_ids, logits, is_real_example):\n",
        "        predictions = tf.argmax(logits, axis=-1, output_type=tf.int32)\n",
        "        loss = tf.metrics.mean(values=per_example_loss, weights=is_real_example)\n",
        "        accuracy = tf.metrics.accuracy(\n",
        "            labels=label_ids, predictions=predictions, weights=is_real_example)\n",
        "        f1_score = tf.contrib.metrics.f1_score(\n",
        "            label_ids,\n",
        "            predictions)\n",
        "        auc = tf.metrics.auc(\n",
        "            label_ids,\n",
        "            predictions)\n",
        "        recall = tf.metrics.recall(\n",
        "            label_ids,\n",
        "            predictions)\n",
        "        precision = tf.metrics.precision(\n",
        "            label_ids,\n",
        "            predictions) \n",
        "        return {\n",
        "            \"eval_accuracy\": accuracy,\n",
        "            \"eval_loss\": loss,\n",
        "            \"f1_score\": f1_score,\n",
        "            \"auc\": auc,\n",
        "            \"precision\": precision,\n",
        "            \"recall\": recall\n",
        "        }\n",
        "\n",
        "      eval_metrics = (metric_fn,\n",
        "                      [per_example_loss, label_ids, logits, is_real_example])\n",
        "      # estimator spec for evalaution\n",
        "      output_spec = tf.contrib.tpu.TPUEstimatorSpec(\n",
        "          mode=mode,\n",
        "          loss=total_loss,\n",
        "          eval_metrics=eval_metrics,\n",
        "          scaffold_fn=scaffold_fn)\n",
        "    else:\n",
        "      # estimator spec for predictions\n",
        "      output_spec = tf.contrib.tpu.TPUEstimatorSpec(\n",
        "          mode=mode,\n",
        "          predictions={\"probabilities\": probabilities},\n",
        "          scaffold_fn=scaffold_fn)\n",
        "    return output_spec\n",
        "\n",
        "  return model_fn\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bNGqR9urFxse",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Define TPU configs\n",
        "if USE_TPU:\n",
        "  tpu_cluster_resolver = tf.contrib.cluster_resolver.TPUClusterResolver(TPU_ADDRESS)\n",
        "else:\n",
        "  tpu_cluster_resolver = None\n",
        "run_config = tf.contrib.tpu.RunConfig(\n",
        "    cluster=tpu_cluster_resolver,\n",
        "    model_dir=OUTPUT_DIR,\n",
        "    save_checkpoints_steps=SAVE_CHECKPOINTS_STEPS,\n",
        "    tpu_config=tf.contrib.tpu.TPUConfig(\n",
        "        iterations_per_loop=ITERATIONS_PER_LOOP,\n",
        "        num_shards=NUM_TPU_CORES,\n",
        "        per_host_input_for_training=tf.contrib.tpu.InputPipelineConfig.PER_HOST_V2))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dXILtEuPF2It",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# create model function for estimator using model function builder\n",
        "model_fn = model_fn_builder(\n",
        "    bert_config=modeling.BertConfig.from_json_file(CONFIG_FILE),\n",
        "    num_labels=len(label_list),\n",
        "    init_checkpoint=INIT_CHECKPOINT,\n",
        "    learning_rate=LEARNING_RATE,\n",
        "    num_train_steps=num_train_steps,\n",
        "    num_warmup_steps=num_warmup_steps,\n",
        "    use_tpu=USE_TPU,\n",
        "    use_one_hot_embeddings=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yh1yVVcRF6xE",
        "colab_type": "code",
        "outputId": "75910485-7374-45a3-b809-f37d5aeef55d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 275
        }
      },
      "source": [
        "estimator = tf.contrib.tpu.TPUEstimator(\n",
        "    use_tpu=USE_TPU,\n",
        "    model_fn=model_fn,\n",
        "    config=run_config,\n",
        "    train_batch_size=TRAIN_BATCH_SIZE,\n",
        "    eval_batch_size=EVAL_BATCH_SIZE,\n",
        "    predict_batch_size=PREDICT_BATCH_SIZE)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Estimator's model_fn (<function model_fn_builder.<locals>.model_fn at 0x7f4c59746048>) includes params argument, but params are not passed to Estimator.\n",
            "INFO:tensorflow:Using config: {'_model_dir': 'gs://quorabert_ml/outputs', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': 1000, '_save_checkpoints_secs': None, '_session_config': allow_soft_placement: true\n",
            "cluster_def {\n",
            "  job {\n",
            "    name: \"worker\"\n",
            "    tasks {\n",
            "      key: 0\n",
            "      value: \"10.71.222.210:8470\"\n",
            "    }\n",
            "  }\n",
            "}\n",
            "isolate_session_state: true\n",
            ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': None, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f4c64e70a90>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': 'grpc://10.71.222.210:8470', '_evaluation_master': 'grpc://10.71.222.210:8470', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1, '_tpu_config': TPUConfig(iterations_per_loop=1000, num_shards=8, num_cores_per_replica=None, per_host_input_for_training=3, tpu_job_name=None, initial_infeed_sleep_secs=None, input_partition_dims=None, eval_training_input_configuration=2, experimental_host_call_every_n_steps=1), '_cluster': <tensorflow.python.distribute.cluster_resolver.tpu_cluster_resolver.TPUClusterResolver object at 0x7f4c6c2ddfd0>}\n",
            "INFO:tensorflow:_TPUContext: eval_on_tpu True\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xTLG_ruUF98Q",
        "colab_type": "code",
        "outputId": "1bb69b67-9e65-4fb7-9ac3-98d69b609c42",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# Train the model.\n",
        "print('QQP on BERT base model normally takes about 1 hour on TPU and 15-20 hours on GPU. Please wait...')\n",
        "print('***** Started training at {} *****'.format(datetime.datetime.now()))\n",
        "print('  Num examples = {}'.format(num_train_examples))\n",
        "print('  Batch size = {}'.format(TRAIN_BATCH_SIZE))\n",
        "tf.logging.info(\"  Num steps = %d\", num_train_steps)\n",
        "# we are using `file_based_input_fn_builder` for creating input function from TF_RECORD file\n",
        "train_input_fn = run_classifier.file_based_input_fn_builder(TRAIN_TF_RECORD,\n",
        "                                                            seq_length=MAX_SEQ_LENGTH,\n",
        "                                                            is_training=True,\n",
        "                                                            drop_remainder=True)\n",
        "estimator.train(input_fn=train_input_fn, max_steps=num_train_steps)\n",
        "print('***** Finished training at {} *****'.format(datetime.datetime.now()))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "QQP on BERT base model normally takes about 1 hour on TPU and 15-20 hours on GPU. Please wait...\n",
            "***** Started training at 2019-12-04 10:17:57.361683 *****\n",
            "  Num examples = 363849\n",
            "  Batch size = 32\n",
            "INFO:tensorflow:  Num steps = 34110\n",
            "INFO:tensorflow:Querying Tensorflow master (grpc://10.71.222.210:8470) for TPU system metadata.\n",
            "INFO:tensorflow:Found TPU system:\n",
            "INFO:tensorflow:*** Num TPU Cores: 8\n",
            "INFO:tensorflow:*** Num TPU Workers: 1\n",
            "INFO:tensorflow:*** Num TPU Cores Per Worker: 8\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:CPU:0, CPU, -1, 16572136444839966562)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:0, TPU, 17179869184, 125794195456464252)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:1, TPU, 17179869184, 7351586087375872416)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:2, TPU, 17179869184, 13132312768162409263)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:3, TPU, 17179869184, 16634641983506438901)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:4, TPU, 17179869184, 15502292326427452463)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:5, TPU, 17179869184, 5257708771083916489)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:6, TPU, 17179869184, 14150966563240120655)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:7, TPU, 17179869184, 17699966468746684564)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU_SYSTEM:0, TPU_SYSTEM, 8589934592, 5871317325771691490)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 17179869184, 6927790739003221205)\n",
            "INFO:tensorflow:Calling model_fn.\n",
            "INFO:tensorflow:Create CheckpointSaverHook.\n",
            "INFO:tensorflow:Done calling model_fn.\n",
            "INFO:tensorflow:TPU job name worker\n",
            "INFO:tensorflow:Graph was finalized.\n",
            "INFO:tensorflow:Restoring parameters from gs://quorabert_ml/outputs/model.ckpt-22740\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/training/saver.py:1069: get_checkpoint_mtimes (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use standard file utilities to get mtimes.\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n",
            "INFO:tensorflow:Saving checkpoints for 22740 into gs://quorabert_ml/outputs/model.ckpt.\n",
            "INFO:tensorflow:Initialized dataset iterators in 0 seconds\n",
            "INFO:tensorflow:Installing graceful shutdown hook.\n",
            "INFO:tensorflow:Creating heartbeat manager for ['/job:worker/replica:0/task:0/device:CPU:0']\n",
            "INFO:tensorflow:Configuring worker heartbeat: shutdown_mode: WAIT_FOR_COORDINATOR\n",
            "\n",
            "INFO:tensorflow:Init TPU system\n",
            "INFO:tensorflow:Initialized TPU in 8 seconds\n",
            "INFO:tensorflow:Starting infeed thread controller.\n",
            "INFO:tensorflow:Starting outfeed thread controller.\n",
            "INFO:tensorflow:Enqueue next (1000) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1000) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Outfeed finished for iteration (0, 0)\n",
            "INFO:tensorflow:Saving checkpoints for 23740 into gs://quorabert_ml/outputs/model.ckpt.\n",
            "INFO:tensorflow:loss = 0.0015939813, step = 23740\n",
            "INFO:tensorflow:Enqueue next (1000) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1000) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Outfeed finished for iteration (1, 0)\n",
            "INFO:tensorflow:Saving checkpoints for 24740 into gs://quorabert_ml/outputs/model.ckpt.\n",
            "INFO:tensorflow:loss = 0.0026807762, step = 24740 (87.529 sec)\n",
            "INFO:tensorflow:global_step/sec: 11.4249\n",
            "INFO:tensorflow:examples/sec: 365.598\n",
            "INFO:tensorflow:Enqueue next (1000) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1000) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Outfeed finished for iteration (2, 0)\n",
            "INFO:tensorflow:Saving checkpoints for 25740 into gs://quorabert_ml/outputs/model.ckpt.\n",
            "INFO:tensorflow:loss = 1.1884652, step = 25740 (86.491 sec)\n",
            "INFO:tensorflow:global_step/sec: 11.5617\n",
            "INFO:tensorflow:examples/sec: 369.973\n",
            "INFO:tensorflow:Enqueue next (1000) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1000) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Outfeed finished for iteration (3, 0)\n",
            "INFO:tensorflow:Saving checkpoints for 26740 into gs://quorabert_ml/outputs/model.ckpt.\n",
            "INFO:tensorflow:loss = 0.000674607, step = 26740 (87.488 sec)\n",
            "INFO:tensorflow:global_step/sec: 11.4305\n",
            "INFO:tensorflow:examples/sec: 365.776\n",
            "INFO:tensorflow:Enqueue next (1000) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1000) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Outfeed finished for iteration (4, 0)\n",
            "INFO:tensorflow:Saving checkpoints for 27740 into gs://quorabert_ml/outputs/model.ckpt.\n",
            "INFO:tensorflow:loss = 0.0030941612, step = 27740 (86.792 sec)\n",
            "INFO:tensorflow:global_step/sec: 11.5219\n",
            "INFO:tensorflow:examples/sec: 368.7\n",
            "INFO:tensorflow:Enqueue next (1000) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1000) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Outfeed finished for iteration (5, 0)\n",
            "INFO:tensorflow:Saving checkpoints for 28740 into gs://quorabert_ml/outputs/model.ckpt.\n",
            "INFO:tensorflow:loss = 0.04027296, step = 28740 (92.217 sec)\n",
            "INFO:tensorflow:global_step/sec: 10.844\n",
            "INFO:tensorflow:examples/sec: 347.007\n",
            "INFO:tensorflow:Enqueue next (1000) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1000) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Outfeed finished for iteration (6, 0)\n",
            "INFO:tensorflow:Saving checkpoints for 29740 into gs://quorabert_ml/outputs/model.ckpt.\n",
            "INFO:tensorflow:loss = 0.004320339, step = 29740 (89.816 sec)\n",
            "INFO:tensorflow:global_step/sec: 11.1338\n",
            "INFO:tensorflow:examples/sec: 356.28\n",
            "INFO:tensorflow:Enqueue next (1000) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1000) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Outfeed finished for iteration (7, 0)\n",
            "INFO:tensorflow:Saving checkpoints for 30740 into gs://quorabert_ml/outputs/model.ckpt.\n",
            "INFO:tensorflow:loss = 0.00198304, step = 30740 (83.359 sec)\n",
            "INFO:tensorflow:global_step/sec: 11.9965\n",
            "INFO:tensorflow:examples/sec: 383.887\n",
            "INFO:tensorflow:Enqueue next (1000) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1000) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Outfeed finished for iteration (8, 0)\n",
            "INFO:tensorflow:Saving checkpoints for 31740 into gs://quorabert_ml/outputs/model.ckpt.\n",
            "INFO:tensorflow:loss = 0.0020579766, step = 31740 (87.800 sec)\n",
            "INFO:tensorflow:global_step/sec: 11.3895\n",
            "INFO:tensorflow:examples/sec: 364.465\n",
            "INFO:tensorflow:Enqueue next (1000) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1000) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Outfeed finished for iteration (9, 0)\n",
            "INFO:tensorflow:Saving checkpoints for 32740 into gs://quorabert_ml/outputs/model.ckpt.\n",
            "INFO:tensorflow:loss = 0.00086584897, step = 32740 (93.815 sec)\n",
            "INFO:tensorflow:global_step/sec: 10.6593\n",
            "INFO:tensorflow:examples/sec: 341.099\n",
            "INFO:tensorflow:Enqueue next (1000) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1000) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Outfeed finished for iteration (10, 0)\n",
            "INFO:tensorflow:Saving checkpoints for 33740 into gs://quorabert_ml/outputs/model.ckpt.\n",
            "INFO:tensorflow:loss = 1.6790272, step = 33740 (84.703 sec)\n",
            "INFO:tensorflow:global_step/sec: 11.8055\n",
            "INFO:tensorflow:examples/sec: 377.777\n",
            "INFO:tensorflow:Enqueue next (370) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (370) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Outfeed finished for iteration (11, 0)\n",
            "INFO:tensorflow:loss = 1.0133668, step = 34110 (22.892 sec)\n",
            "INFO:tensorflow:global_step/sec: 16.1651\n",
            "INFO:tensorflow:examples/sec: 517.284\n",
            "INFO:tensorflow:Saving checkpoints for 34110 into gs://quorabert_ml/outputs/model.ckpt.\n",
            "INFO:tensorflow:Stop infeed thread controller\n",
            "INFO:tensorflow:Shutting down InfeedController thread.\n",
            "INFO:tensorflow:InfeedController received shutdown signal, stopping.\n",
            "INFO:tensorflow:Infeed thread finished, shutting down.\n",
            "INFO:tensorflow:infeed marked as finished\n",
            "INFO:tensorflow:Stop output thread controller\n",
            "INFO:tensorflow:Shutting down OutfeedController thread.\n",
            "INFO:tensorflow:OutfeedController received shutdown signal, stopping.\n",
            "INFO:tensorflow:Outfeed thread finished, shutting down.\n",
            "INFO:tensorflow:outfeed marked as finished\n",
            "INFO:tensorflow:Shutdown TPU system.\n",
            "INFO:tensorflow:Loss for final step: 1.0133668.\n",
            "INFO:tensorflow:training_loop marked as finished\n",
            "***** Finished training at 2019-12-04 10:36:49.088856 *****\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yw2uGkyLGJXo",
        "colab_type": "code",
        "outputId": "06379616-7ef9-4d36-f6ff-42d2d3bbab93",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 231
        }
      },
      "source": [
        "# eval the model on train set.\n",
        "print('***** Started Train Set evaluation at {} *****'.format(datetime.datetime.now()))\n",
        "print('  Num examples = {}'.format(num_train_examples))\n",
        "print('  Batch size = {}'.format(EVAL_BATCH_SIZE))\n",
        "# eval input function for train set\n",
        "train_eval_input_fn = run_classifier.file_based_input_fn_builder(TRAIN_TF_RECORD,\n",
        "                                                           seq_length=MAX_SEQ_LENGTH,\n",
        "                                                           is_training=False,\n",
        "                                                           drop_remainder=True)\n",
        "# evalute on train set\n",
        "result = estimator.evaluate(input_fn=train_eval_input_fn, \n",
        "                            steps=int(num_train_examples/EVAL_BATCH_SIZE))\n",
        "print('***** Finished evaluation at {} *****'.format(datetime.datetime.now()))\n",
        "print(\"***** Eval results *****\")\n",
        "for key in sorted(result.keys()):\n",
        "  print('  {} = {}'.format(key, str(result[key])))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-6be9155299d1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'***** Started Train Set evaluation at {} *****'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdatetime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdatetime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'  Num examples = {}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_train_examples\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'  Batch size = {}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mEVAL_BATCH_SIZE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# eval input function for train set\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m train_eval_input_fn = run_classifier.file_based_input_fn_builder(TRAIN_TF_RECORD,\n",
            "\u001b[0;31mNameError\u001b[0m: name 'datetime' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HvI3xohPSNSM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "EVAL_TF_RECORD = os.path.join(OUTPUT_DIR, \"eval.tf_record\")\n",
        "eval_examples = processor.get_dev_examples(TASK_DATA_DIR)\n",
        "num_eval_examples = len(eval_examples)\n",
        "run_classifier.file_based_convert_examples_to_features(eval_examples, label_list, MAX_SEQ_LENGTH, tokenizer, EVAL_TF_RECORD)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_lcG85TOU7c1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print('***** Started Dev Set evaluation at {} *****'.format(datetime.datetime.now()))\n",
        "print('  Num examples = {}'.format(num_eval_examples))\n",
        "print('  Batch size = {}'.format(EVAL_BATCH_SIZE))\n",
        "\n",
        "# eval input function for dev set\n",
        "eval_input_fn = run_classifier.file_based_input_fn_builder(EVAL_TF_RECORD,\n",
        "                                                           seq_length=MAX_SEQ_LENGTH,\n",
        "                                                           is_training=False,\n",
        "                                                           drop_remainder=True)\n",
        "# evalute on dev set\n",
        "result = estimator.evaluate(input_fn=eval_input_fn, steps=int(num_eval_examples/EVAL_BATCH_SIZE))\n",
        "print('***** Finished evaluation at {} *****'.format(datetime.datetime.now()))\n",
        "print(\"***** Eval results *****\")\n",
        "for key in sorted(result.keys()):\n",
        "  print('  {} = {}'.format(key, str(result[key])))"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}